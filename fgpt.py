# â–ˆ â–ˆâ€ƒâ–ˆâ€ƒâ–ˆâ–„â–€â€ƒâ–„â–€â–ˆâ€ƒâ–ˆâ–€â–„â–€â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆ â–ˆ
# â–ˆâ–€â–ˆâ€ƒâ–ˆâ€ƒâ–ˆ â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆ â–€ â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–€â–„â€ƒâ–ˆâ–„â–ˆ

# ğŸ”’ Licensed under the GNU GPLv3
# ğŸŒ https://www.gnu.org/licenses/agpl-3.0.html
# ğŸ‘¤ https://t.me/hikamoru

# required: groq


import logging
import requests
from typing import Optional

from datetime import datetime

from groq import Groq
from groq.types.chat import ChatCompletion

from .. import loader, utils

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@loader.module("FreeGPT", "shizumods")
class FreeGPT(loader.Module):
    """Advanced Free Alternative to ChatGPT with Enhanced Features"""

    strings = {
        "no_input": "â— Reply to a message or provide text input",
        "no_token": "ğŸš« GROQ API token not configured. Please set it in module config.",
        "processing": "ğŸš€ Processing your request...",
        "error": "âš ï¸ An error occurred: {error}",
        "response": (
            "<emoji id='5325695795624682172'>ğŸ±</emoji> <b>Your Question:</b> <code>{question}</code>\n\n"
            "<emoji id='5359726582447487916'>ğŸ“±</emoji> <b>Answer:</b> {answer}\n\n"
            "<emoji id='5947553854030614234'>ğŸ“Š</emoji> Tokens Used: <code>{tokens}</code> | Model: <code>{model}</code>"
        ),
        "_cfg_doc_groq_token": "Your GROQ API token from https://console.groq.com/keys",
        "_cfg_doc_default_model": "Default AI model to use",
        "_cfg_doc_max_tokens": "Maximum tokens for response",
        "_cfg_doc_temperature": "Creativity/randomness of response",
    }

    strings_ru = {
        "no_input": "â— ĞÑ‚Ğ²ĞµÑ‚ÑŒÑ‚Ğµ Ğ½Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸Ğ»Ğ¸ ÑƒĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ñ‚ĞµĞºÑÑ‚",
        "no_token": "ğŸš« Ğ¢Ğ¾ĞºĞµĞ½ GROQ API Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, ÑƒĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ ĞµĞ³Ğ¾ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ.",
        "processing": "ğŸš€ ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ Ğ²Ğ°Ñˆ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ...",
        "error": "âš ï¸ ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {error}",
        "response": (
            "<emoji id='5325695795624682172'>ğŸ±</emoji> <b>Ğ’Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ:</b> <code>{question}</code>\n\n"
            "<emoji id='5359726582447487916'>ğŸ“±</emoji> <b>ĞÑ‚Ğ²ĞµÑ‚:</b> {answer}\n\n"
            "<emoji id='5947553854030614234'>ğŸ“Š</emoji> Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: <code>{tokens}</code> | ĞœĞ¾Ğ´ĞµĞ»ÑŒ: <code>{model}</code>"
        ),
        "_cfg_doc_groq_token": "Ğ’Ğ°Ñˆ Ñ‚Ğ¾ĞºĞµĞ½ GROQ API Ñ https://console.groq.com/keys",
        "_cfg_doc_default_model": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ˜Ğ˜ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
        "_cfg_doc_max_tokens": "ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°",
        "_cfg_doc_temperature": "ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ/ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            "groq_token",
            None,
            lambda: self.strings["_cfg_doc_groq_token"],
            "default_model",
            "llama3-8b-8192",
            lambda: self.strings["_cfg_doc_default_model"],
            "max_tokens",
            2048,
            lambda: self.strings["_cfg_doc_max_tokens"],
            "temperature",
            0.7,
            lambda: self.strings["_cfg_doc_temperature"],
        )
        self._client = None

    def _init_client(self):
        """Initialize Groq client if not already initialized"""
        if not self._client and self.config["groq_token"]:
            self._client = Groq(api_key=self.config["groq_token"])
        return self._client

    @loader.command()
    async def fgpt_models(self, app, message):
        url = "https://api.groq.com/openai/v1/models"
        headers = {
            "Authorization": f"Bearer {self.config['groq_token']}",
            "Content-Type": "application/json",
        }

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()

            models = response.json().get("data", [])

            grouped_models = {}
            for model in models:
                owner = model.get("owned_by", "Unknown")
                if owner not in grouped_models:
                    grouped_models[owner] = []
                grouped_models[owner].append(model)

            model_details = []
            for owner, owner_models in sorted(grouped_models.items()):
                model_details.append(f"ğŸ¢ {owner}:")
                for model in sorted(owner_models, key=lambda x: x["id"]):
                    model_info = (
                        f"  ğŸ”¹ {model['id']}\n"
                        f"    â€¢ Context Window: {model.get('context_window', 'N/A')} tokens\n"
                        f"    â€¢ Status: {'ğŸŸ¢ Active' if model.get('active', False) else 'ğŸ”´ Inactive'}\n"
                        f"    â€¢ Created: {datetime.fromtimestamp(model.get('created', 0)).strftime('%Y-%m-%d')}"
                    )
                    model_details.append(model_info)
                model_details.append("")

            response_text = "\n".join(model_details).strip()

            max_message_length = 4096
            if len(response_text) > max_message_length:
                chunks = [
                    response_text[i : i + max_message_length]
                    for i in range(0, len(response_text), max_message_length)
                ]
                for chunk in chunks:
                    await message.reply(chunk)
            else:
                await message.reply(response_text)

        except Exception as e:
            logger.error(f"Error in fgpt_models command: {e}")
            await message.reply(self.strings["error"].format(error=str(e)))

    @loader.command()
    async def fgpt(self, app, message):
        """Process user's text input or replied message"""
        try:
            txt = await self._extract_text(message)
            if not txt:
                await message.reply(self.strings["no_input"])
                return

            if not self.config["groq_token"]:
                await message.reply(self.strings["no_token"])
                return

            processing_msg = await message.answer(self.strings["processing"])

            response = await self._generate_response(txt)

            await processing_msg.edit(
                self.strings["response"].format(
                    question=txt,
                    answer=response.choices[0].message.content,
                    tokens=response.usage.total_tokens,
                    model=response.model,
                )
            )

        except Exception as e:
            logger.error(f"Error in fgpt command: {e}")
            await message.reply(self.strings["error"].format(error=str(e)))

    async def _extract_text(self, message) -> Optional[str]:
        """Extract text from message or reply"""
        if args := utils.get_args_raw(message):
            return args

        reply = message.reply_to_message
        return reply.text or reply.caption if reply else None

    async def _generate_response(self, prompt: str) -> ChatCompletion:
        """Generate AI response with configurable parameters"""
        client = self._init_client()

        return client.chat.completions.create(
            model=self.config["default_model"],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=self.config["max_tokens"],
            temperature=self.config["temperature"],
        )
